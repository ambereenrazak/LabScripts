{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lucky Last Lab 16: visualising, interpolating, and deconvoluting data\n",
    "\n",
    "In this lab, we'll look at a number of different ways to visualise and plot 1D and 2D data. As a final exercise, we'll combine this with the discrete Fourier transform from lab 15 to produce what looks like a miraculous \"unblurring\" of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with a simple example to warm up. A data set called `scores.txt` is provided, containing the results of 1000 measurements of some scalar quantity.\n",
    "\n",
    "**Use `np.loadtxt` to import these data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the *array methods* `min`, `max`, `mean`, and `std` to determine some summary statistics of these data.** *Hint:* if you have an array variable `my_array`, the syntax of these methods is `my_array.max()` and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, nothing replaces looking at these data directly. A suitable plot type would be a *histogram*, which can be made using the `plt.hist()` function. **Plot a histogram of these data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, that doesn't look quite like a normal distribution. **Try increasing the number of bins** (columns), using the optional `bins=...` argument to `hist()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you conclude about the distribution of these data?** For instance, how many *modes* (peaks of probability) are there? Do you think these data are drawn from a Gaussian distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try loading some 2D data. An example is provided as `score_pairs.txt`. This array has two columns: the two points in each row correspond to two different measurements on the same sample.\n",
    "\n",
    "**Load these data using `np.loadtxt` as before. Use `plt.hist2d`** (or, if you like, `plt.hexbin`) **to plot a 2D histogram of them. Where are most of the points concentrated?** Again, you may want to play with the number of bins.\n",
    "\n",
    "*Hint*: Like `plot`, `hist2d` requires two arguments, one of x values and one of y. Thus you will need to pass the first and second column separately, using appropriate array slicing. Consult the `shape` of the data array if you are uncertain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sort of plot is appropriate when data come as pairs of measurements: for instance, the height and weight of a person, or the $x$ and $y$ coordinates where a particular plant species was observed.\n",
    "\n",
    "Another sort of 2D data occurs when we make measurements as a function of two dependent variables – for instance, measuring the height of a mountain as a function of $x$ and $y$. The easiest case is where $x$ and $y$ form a regular grid. Data of this sort are provided as `2dgrid.txt`. \n",
    "\n",
    "**Load these data using `np.loadtxt`. Plot them using `plt.imshow`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note two peculiarity about this plot: first, the origin is by default taken to be in the *top* left corner, which is the convention for computing but not usually helpful in science. To fix this, **use the optional argument `origin='lower'`.** Second, there is no information in the grid of data about what the $x$ and $y$ coordinates actually represent. To fix this, **use the optional `extent` argument**, given that these data represent an $x$ span of $-$0.7 to 0.35 and a $y$ span of 1.55 to 2.4. **Check your results show a peak at $(0, 2)$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▶ **CHECKPOINT 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same methods `max`, `min`, `mean`, and `std` to characterise 2D data, but there is an extra twist here: the optional `axis` argument lets us specify a single axis to look over. To see what this does, consider the following simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.array([[1, 2],[3, 4]])\n",
    "print(my_array)\n",
    "print(my_array.max())\n",
    "print(my_array.max(axis=0))\n",
    "print(my_array.max(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Use this method to **calculate the maximum value in *every row* of these data, and plot this as a function of $y$.**\n",
    "\n",
    "*Hint*: use a suitable `linspace` to give the $y$ values. You can determine how many points are necessary using the `shape` property of an array: you'll need the first element of this array (why?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly **calculate the maximum value in *every column* of these data, and plot this as a function of $x$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a different tack, by plotting a function in two dimensions. We can do this with the help of the `np.meshgrid` function. **Examine the following code and see if you can convince yourself** – looking at the documentation as well if you like – **of what this function does.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.meshgrid((0, 1, 2), (4, 5, 6, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this as follows, to calculate *Himmelblau's function* $f(x,y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Himmelblau's function\n",
    "x, y = np.linspace(-5, 5), np.linspace(-5, 5)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = (X**2 + Y - 11)**2 + (X + Y**2 - 7)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `contourf` function is used to plot \"contours\" joining points that have equal values of this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.contour(X, Y, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default settings here don't seem to be particularly helpful. The fourth, optional argument of `contourf` can either be an integer, which is interpreted as a number of contours to draw, or a list/tuple/array of values, which is interpreted as values at which to draw contours. **Find a suitable value of this argument to show clearly where the local maxima, local minima, and saddle points are in the given range $-5 \\leq x, y \\leq 5$. How many of each are there?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `contourf` function relies on the data being provided on a grid. If they are not, we first have to perform a separate interpolation step, using the `griddata` function from `scipy.interpolate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data points drawn from this same function, presented in three columns ($x, y, f(x,y)$), are available as `nogrid.txt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_gridded = np.loadtxt('nogrid.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax of `nogrid` is a little tricky, so I've provided an example for you. The first argument is the set of $(x, y)$ points; the second is the values of $f(x,y)$, and the third is the grid to interpolate onto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded = griddata(not_gridded[:,0:2], not_gridded[:,2], (X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `contour` to **plot the newly gridded data** `gridded` on the same `X, Y` grid as before. Use `plot` to **plot the ungridded data points** `not_gridded[:,0]` against `not_gridded[:,1]` **on the same figure**. You should see that the positions of the available data are heavily influencing the contours drawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat the gridding step using the optional argument `method='cubic'`, a more sophisticated interpolation routine. Make a new plot of these data, again with the ungridded data points on top. Check that your results are more similar to the original function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▶ **CHECKPOINT 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deconvolution\n",
    "\n",
    "Our final task will combine 2D plotting with Fourier transforms to \"undo\" the blurring that has made an image unreadable.\n",
    "\n",
    "A blurred image is provided as `deconvolve.npy`. **Use `np.load`** (NB, *not* `loadtxt`) **to load this** (call it `blurred`) **and `plt.imshow` to plot it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that this image has been blurred with a Gaussian blur, so need to set up a suitable Gaussian to deconvolve with. Once again we use `meshgrid`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y = np.arange(-300, 300, 1)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "sigma = 10\n",
    "blurrer = np.exp(-(X**2 + Y**2)/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check you understand what the code above does, then use `imshow` to plot the array `blurrer`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, `blurrer` follows the usual scientific convention, with the origin in the middle of the array. We need to shift it to follow the discrete Fourier transform convention, with the origin at the beginning of each axis, for which you may recall we can use the `fftshift` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurrer = np.fft.fftshift(blurrer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Use `np.fft.fft2`**, the 2D Fourier transform function, **to transform both `blurrer` and `blurred`, calling your results `ftblurrer` and `ftblurred`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Rather than plotting these results directly, we will plot the regions where there is significant signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(abs(ftblurrer) > 1e-10)\n",
    "plt.figure()\n",
    "plt.imshow(abs(ftblurred) > 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that only low-frequency components (*i.e.*, the corners of the plot) are present in both FTs.\n",
    "**Adjust `sigma` from the `blurrer` calculation until these regions above $10^{-7}$ are about the same size, but slightly larger in `blurrer` than `blurred`.** At this point, we are using all the available information.\n",
    "\n",
    "We're now ready to deconvolve. We divide through by `ftblurrer` *only in those regions where this value is not so small that it will cause problems*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftblurred[abs(ftblurrer) > 1e-10] /= ftblurrer[abs(ftblurrer) > 1e-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now **use `np.fft.ifft2` to inverse Fourier transform `ftblurred`, and `imshow` to plot it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint:* If your result is still blurred, `sigma` is too small; if it looks completely unlike the input, `sigma` is too large.\n",
    "\n",
    "▶ **CHECKPOINT 3**\n",
    "\n",
    "**Extension:** Experiment with different `sigma` values. What happens when this value is too small or too large? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
